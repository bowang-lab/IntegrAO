{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New patient classification with incomplete omics profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and IntegrAO code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import snf\n",
    "from sklearn.cluster import spectral_clustering\n",
    "from sklearn.metrics import v_measure_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "import umap\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory of \"integrao\" to the Python path\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from integrao.dataset import GraphDataset\n",
    "from integrao.main import dist2\n",
    "from integrao.integrater import integrao_integrater, integrao_predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "neighbor_size = 20\n",
    "embedding_dims = 64\n",
    "fusing_iteration = 30\n",
    "normalization_factor = 1.0\n",
    "alighment_epochs = 1000\n",
    "beta = 1.0\n",
    "mu = 0.5\n",
    "\n",
    "\n",
    "dataset_name = 'cancer_omics_prediction'\n",
    "cluster_number = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create result dir\n",
    "result_dir = os.path.join(\n",
    "    module_path, \"results/{}\".format(dataset_name)\n",
    ")\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 367)\n",
      "(500, 131)\n",
      "(500, 160)\n",
      "(500, 2)\n",
      "finish loading data!\n"
     ]
    }
   ],
   "source": [
    "testdata_dir = os.path.join(module_path, \"data/omics/\")\n",
    "\n",
    "methyl_ = os.path.join(testdata_dir, \"omics1.txt\")\n",
    "expr_ = os.path.join(testdata_dir, \"omics2.txt\")\n",
    "protein_ = os.path.join(testdata_dir, \"omics3.txt\")\n",
    "truelabel = os.path.join(testdata_dir, \"clusters.txt\")\n",
    "\n",
    "\n",
    "methyl = pd.read_csv(methyl_, index_col=0, delimiter=\"\\t\")\n",
    "expr = pd.read_csv(expr_, index_col=0, delimiter=\"\\t\")\n",
    "protein = pd.read_csv(protein_, index_col=0, delimiter=\"\\t\")\n",
    "truelabel = pd.read_csv(truelabel, index_col=0, delimiter=\"\\t\")\n",
    "\n",
    "methyl = np.transpose(methyl)\n",
    "expr = np.transpose(expr)\n",
    "protein = np.transpose(protein)\n",
    "print(methyl.shape)\n",
    "print(expr.shape)\n",
    "print(protein.shape)\n",
    "print(truelabel.shape)\n",
    "print(\"finish loading data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random stratified-subsample 80%-20% samples to simulate the senario of incomplete omics dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjects</th>\n",
       "      <th>cluster.id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subject5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>subject496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>subject497</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>subject498</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>subject499</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>subject500</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subjects  cluster.id\n",
       "1      subject1           6\n",
       "2      subject2           7\n",
       "3      subject3           9\n",
       "4      subject4           6\n",
       "5      subject5           4\n",
       "..          ...         ...\n",
       "496  subject496           1\n",
       "497  subject497          14\n",
       "498  subject498           4\n",
       "499  subject499           1\n",
       "500  subject500           9\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truelabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_patient = methyl.index\n",
    "y = truelabel['cluster.id'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(common_patient, y, stratify=y, test_size=0.2)\n",
    "\n",
    "# get the reference and query data\n",
    "methyl_ref = methyl.loc[X_train]\n",
    "expr_ref = expr.loc[X_train]\n",
    "protein_ref = protein.loc[X_train]\n",
    "\n",
    "methyl_query = methyl.loc[X_test]\n",
    "expr_query = expr.loc[X_test]\n",
    "protein_query = protein.loc[X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's intergrate the reference data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start indexing input expression matrices!\n",
      "Common sample between view0 and view1: 400\n",
      "Common sample between view0 and view2: 400\n",
      "Common sample between view1 and view2: 400\n",
      "Neighbor size: 20\n",
      "Start applying diffusion!\n",
      "Diffusion ends! Times: 8.610264778137207s\n",
      "Starting unsupervised exmbedding extraction!\n",
      "Dataset 0: (400, 367)\n",
      "Dataset 1: (400, 131)\n",
      "Dataset 2: (400, 160)\n",
      "epoch 0: loss 27.511960983276367, align_loss:0.731402\n",
      "epoch 100: loss 19.206762313842773, align_loss:0.109023\n",
      "epoch 200: loss 0.6979491114616394, align_loss:0.062670\n",
      "epoch 300: loss 0.697240948677063, align_loss:0.062080\n",
      "epoch 400: loss 0.69642174243927, align_loss:0.061394\n",
      "epoch 500: loss 0.6955264210700989, align_loss:0.060751\n",
      "epoch 600: loss 0.6945570707321167, align_loss:0.060056\n",
      "epoch 700: loss 0.6935387253761292, align_loss:0.059397\n",
      "epoch 800: loss 0.692470371723175, align_loss:0.058727\n",
      "epoch 900: loss 0.6913514733314514, align_loss:0.058086\n",
      "Manifold alignment ends! Times: 20.610440015792847s\n"
     ]
    }
   ],
   "source": [
    "# Initialize integrater\n",
    "integrater = integrao_integrater(\n",
    "    [methyl_ref, expr_ref, protein_ref],\n",
    "    dataset_name,\n",
    "    modalities_name_list=[\"methyl\", \"expr\", \"protein\"],   # used for naming the incomplete modalities during new sample inference\n",
    "    neighbor_size=neighbor_size,\n",
    "    embedding_dims=embedding_dims,\n",
    "    fusing_iteration=fusing_iteration,\n",
    "    normalization_factor=normalization_factor,\n",
    "    alighment_epochs=alighment_epochs,\n",
    "    beta=beta,\n",
    "    mu=mu,\n",
    ")\n",
    "# data indexing\n",
    "fused_networks = integrater.network_diffusion()\n",
    "embeds_final, S_final, model = integrater.unsupervised_alignment()\n",
    "\n",
    "# save the model for fine-tuning\n",
    "torch.save(model.state_dict(), os.path.join(result_dir, \"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IntegrAO for clustering reference 400 samples NMI score:  1.0\n"
     ]
    }
   ],
   "source": [
    "labels = spectral_clustering(S_final, n_clusters=cluster_number)\n",
    "\n",
    "# select from truelabel based on the 'subjects' column in embeds_final\n",
    "truelabel_filtered = truelabel[truelabel['subjects'].isin(embeds_final.index)]\n",
    "truelabel_filtered = truelabel_filtered.sort_values('subjects')['cluster.id'].tolist()\n",
    "\n",
    "score_all = v_measure_score(truelabel_filtered, labels)\n",
    "print(\"IntegrAO for clustering reference 400 samples NMI score: \", score_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to perform fine-tuning using on the ground true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster.id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subject2</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject3</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject6</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject495</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject496</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject497</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject500</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cluster.id\n",
       "subjects              \n",
       "subject2             6\n",
       "subject3             8\n",
       "subject4             5\n",
       "subject5             3\n",
       "subject6            10\n",
       "...                ...\n",
       "subject495           8\n",
       "subject496           0\n",
       "subject497          13\n",
       "subject499           0\n",
       "subject500           8\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truelabel_sub = truelabel[truelabel['subjects'].isin(embeds_final.index)]\n",
    "truelabel_sub = truelabel_sub.set_index('subjects')\n",
    "\n",
    "# minus 1 for the cluster id to avoid CUDA error\n",
    "truelabel_sub['cluster.id'] = truelabel_sub['cluster.id'] - 1\n",
    "truelabel_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting supervised fineting!\n",
      "Dataset 0: (400, 367)\n",
      "Dataset 1: (400, 131)\n",
      "Dataset 2: (400, 160)\n",
      "IntegrAO(\n",
      "  (feature): ModuleList(\n",
      "    (0): GraphSAGE(367, 64, num_layers=2)\n",
      "    (1): GraphSAGE(131, 64, num_layers=2)\n",
      "    (2): GraphSAGE(160, 64, num_layers=2)\n",
      "  )\n",
      "  (feature_show): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (pred_head): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    (3): Linear(in_features=32, out_features=15, bias=True)\n",
      "  )\n",
      ")\n",
      "Loaded pre-trained model with success.\n",
      "epoch 0: loss 3.6955952644348145, kl_loss:0.641008, align_loss:0.054019, clf_loss:3.000568\n",
      "epoch 100: loss 0.6305103302001953, kl_loss:0.589171, align_loss:0.041248, clf_loss:0.000092\n",
      "epoch 200: loss 0.6225103735923767, kl_loss:0.582280, align_loss:0.040149, clf_loss:0.000082\n",
      "epoch 300: loss 0.6215760707855225, kl_loss:0.581475, align_loss:0.040019, clf_loss:0.000082\n",
      "epoch 400: loss 0.6204578876495361, kl_loss:0.580505, align_loss:0.039872, clf_loss:0.000081\n",
      "epoch 500: loss 0.6191694140434265, kl_loss:0.579405, align_loss:0.039684, clf_loss:0.000081\n",
      "epoch 600: loss 0.6176994442939758, kl_loss:0.578089, align_loss:0.039530, clf_loss:0.000081\n",
      "epoch 700: loss 0.6160817742347717, kl_loss:0.576677, align_loss:0.039322, clf_loss:0.000082\n",
      "Manifold alignment ends! Times: 40.30371856689453s\n"
     ]
    }
   ],
   "source": [
    "embeds_final, S_final, model, preds = integrater.classification_finetuning(truelabel_sub, result_dir, finetune_epochs=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to perform inference on query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start indexing input expression matrices!\n",
      "Common sample between view0 and view1: 500\n",
      "Common sample between view0 and view2: 500\n",
      "Common sample between view1 and view2: 500\n",
      "Neighbor size: 20\n",
      "Start applying diffusion!\n",
      "Diffusion ends! Times: 11.70268440246582s\n"
     ]
    }
   ],
   "source": [
    "# Network fusion for the whole graph\n",
    "predictor = integrao_predictor(\n",
    "    [methyl, expr, protein],\n",
    "    dataset_name,\n",
    "    modalities_name_list=[\"methyl\", \"expr\", \"protein\"], \n",
    "    neighbor_size=neighbor_size,\n",
    "    embedding_dims=embedding_dims,\n",
    "    fusing_iteration=fusing_iteration,\n",
    "    normalization_factor=normalization_factor,\n",
    "    alighment_epochs=alighment_epochs,\n",
    "    beta=beta,\n",
    "    mu=mu,\n",
    ")\n",
    "# data indexing\n",
    "fused_networks = predictor.network_diffusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# helper function to get the metrics on test set\n",
    "def get_metrics(preds, preds_index, X_test, y_test):\n",
    "\n",
    "    pred_df = pd.DataFrame(data=preds, index=preds_index)\n",
    "    pred_df_test = pred_df.loc[X_test]\n",
    "\n",
    "    # add 1 back to the cluster id\n",
    "    pred_df_test = pred_df_test + 1\n",
    "\n",
    "    f1_micro = f1_score(y_test, pred_df_test, average='micro')\n",
    "    f1_weighted = f1_score(y_test, pred_df_test, average='weighted')\n",
    "    acc = accuracy_score(y_test, pred_df_test)\n",
    "\n",
    "    return f1_micro, f1_weighted, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using one modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "methyl f1_micro:  0.97\n",
      "methyl f1_weight:  0.9686984126984127\n",
      "methyl acc:  0.97\n"
     ]
    }
   ],
   "source": [
    "# for methyl\n",
    "preds = predictor.inference(model, new_datasets=[methyl], modalities_names=[\"methyl\"])\n",
    "\n",
    "f1_micro, f1_weight, acc = get_metrics(preds, methyl.index, X_test, y_test)\n",
    "\n",
    "print(\"methyl f1_micro: \", f1_micro)\n",
    "print(\"methyl f1_weight: \", f1_weight)\n",
    "print(\"methyl acc: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expr f1_micro:  1.0\n",
      "expr f1_weight:  1.0\n",
      "expr acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# for expr\n",
    "preds = predictor.inference(model, new_datasets=[expr], modalities_names=[\"expr\"])\n",
    "\n",
    "f1_micro, f1_weight, acc = get_metrics(preds, expr.index, X_test, y_test)\n",
    "\n",
    "print(\"expr f1_micro: \", f1_micro)\n",
    "print(\"expr f1_weight: \", f1_weight)\n",
    "print(\"expr acc: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protein f1_micro:  1.0\n",
      "protein f1_weight:  1.0\n",
      "protein acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# for protein\n",
    "preds = predictor.inference(model, new_datasets=[protein], modalities_names=[\"protein\"])\n",
    "\n",
    "f1_micro, f1_weight, acc = get_metrics(preds, protein.index, X_test, y_test)\n",
    "\n",
    "\n",
    "print(\"protein f1_micro: \", f1_micro)\n",
    "print(\"protein f1_weight: \", f1_weight)\n",
    "print(\"protein acc: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "methyl+expr f1_micro:  1.0\n",
      "methyl+expr f1_weight:  1.0\n",
      "methyl+expr acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# methyl and expr\n",
    "preds = predictor.inference(model, new_datasets=[methyl, expr], modalities_names=[\"methyl\", \"expr\"])\n",
    "\n",
    "f1_micro, f1_weight, acc = get_metrics(preds, methyl.index, X_test, y_test)\n",
    "\n",
    "print(\"methyl+expr f1_micro: \", f1_micro)\n",
    "print(\"methyl+expr f1_weight: \", f1_weight)\n",
    "print(\"methyl+expr acc: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "methyl+protein f1_micro:  1.0\n",
      "methyl+protein f1_weight:  1.0\n",
      "methyl+protein acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# methyl and protein\n",
    "preds = predictor.inference(model, new_datasets=[methyl, protein], modalities_names=[\"methyl\", \"protein\"])\n",
    "\n",
    "f1_micro, f1_weight, acc = get_metrics(preds, methyl.index, X_test, y_test)\n",
    "\n",
    "print(\"methyl+protein f1_micro: \", f1_micro)\n",
    "print(\"methyl+protein f1_weight: \", f1_weight)\n",
    "print(\"methyl+protein acc: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expr+protein f1_micro:  1.0\n",
      "expr+protein f1_weight:  1.0\n",
      "expr+protein acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# expr and protein\n",
    "preds = predictor.inference(model, new_datasets=[expr, protein], modalities_names=[\"expr\", \"protein\"])\n",
    "\n",
    "f1_micro, f1_weight, acc = get_metrics(preds, expr.index, X_test, y_test)\n",
    "\n",
    "print(\"expr+protein f1_micro: \", f1_micro)\n",
    "print(\"expr+protein f1_weight: \", f1_weight)\n",
    "print(\"expr+protein acc: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "methyl+expr+protein f1_micro:  1.0\n",
      "methyl+expr+protein f1_weight:  1.0\n",
      "methyl+expr+protein acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# methyl, expr and protein\n",
    "preds = predictor.inference(model, new_datasets=[methyl, expr, protein], modalities_names=[\"methyl\", \"expr\", \"protein\"])\n",
    "\n",
    "f1_micro, f1_weight, acc = get_metrics(preds, methyl.index, X_test, y_test)\n",
    "\n",
    "print(\"methyl+expr+protein f1_micro: \", f1_micro)\n",
    "print(\"methyl+expr+protein f1_weight: \", f1_weight)\n",
    "print(\"methyl+expr+protein acc: \", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
